# False Positive Rate (FPR)
fpr2 <- fp2 / (tn2 + fp2)
fpr2
# False Negative Rate (FNR)
fnr2 <- fn2 / (tp2 +fn2)
fnr2
cat("True Positive Rate (TPR):", tpr2, "\n")
cat("True Negative Rate (TNR):", tnr2, "\n")
cat("False Positive Rate (FPR):", fpr2, "\n")
cat("False Negative Rate (FNR):", fnr2, "\n")
#Logistic Regression
# convert output as factor
smoke_updated_no_outliers$Fire.Alarm <- as.factor(smoke_updated_no_outliers$Fire.Alarm)
colnames(smoke_updated_no_outliers)
smoke_updated_no_outliers$Fire.Alarm <- as.factor(smoke_updated_no_outliers$Fire.Alarm)
str(smoke_updated_no_outliers)
smoke_updated_no_outliers$Pressure.scaled <- scale(smoke_updated_no_outliers$Pressure.hPa.)
colnames(smoke_updated_no_outliers)
write_xlsx(smoke_updated_no_outliers, "smoke_updated_no_outliers.csv")
logit.reg <- glm(Fire.Alarm ~.,
data = smoke_updated_no_outliers.train, family = "binomial")
summary(logit.reg)
vif(logit.reg)
logit.reg.scaled <- glm(
formula = as.formula("Fire.Alarm ~ UTC + Temperature.C. + Humidity... + TVOC.ppb. +
eCO2.ppm. + Raw.H2 + Raw.Ethanol  +
PM1.0 + NC2.5"),
family = binomial(link = "logit"),
data = smoke_updated_no_outliers
)
# Check the model summary
summary(logit.reg.scaled)
library(car)
vif(logit.reg)
logitPredict1 <- predict(logit.reg, smoke_updated_no_outliers.train, type = "response")
logitPredictClass1 <- ifelse(logitPredict1 > 0.5, 1, 0)
actual1 <- smoke_updated_no_outliers.train$Fire.Alarm
predict1 <- logitPredictClass1
length(actual1)
length(predict1)
cm1 <- table(predict1, actual1)
cm1
tp3 <- cm1[2,2]
tn3 <- cm1[1,1]
fp3 <- cm1[2,1]
fn3 <- cm1[1,2]
# Accuracy
accuracy1 <- (tp3 + tn3) / (tp3 + tn3 + fp3 + fn3)
accuracy1
# True Positive Rate (TPR) or Recall
tpr3 <- tp3 / (tp3 + fn3)
tpr3
# True Negative Rate (TNR) or Specificity
tnr3 <- tn3 / (tn3 + fp3)
tnr3
# False Positive Rate (FPR)
fpr3 <- fp3 / (tn3 + fp3)
fpr3
# False Negative Rate (FNR)
fnr3 <- fn3 / (tp3 +fn3)
fnr3
# Print out the results
cat("Accuracy:", accuracy1, "\n")
cat("True Positive Rate (TPR):", tpr3, "\n")
cat("True Negative Rate (TNR):", tnr3, "\n")
cat("False Positive Rate (FPR):", fpr3, "\n")
cat("False Negative Rate (FNR):", fnr3, "\n")
logitPredict2 <- predict(logit.reg, smoke_updated_no_outliers.test, type = "response")
logitPredictClass2 <- ifelse(logitPredict2 > 0.5, 1, 0)
actual2 <- smoke_updated_no_outliers.test$Fire.Alarm
predict2 <- logitPredictClass2
length(actual2)
length(predict2)
cm2 <- table(predict2, actual2)
cm2
tp4 <- cm2[2,2]
tn4 <- cm2[1,1]
fp4 <- cm2[2,1]
fn4 <- cm2[1,2]
# Accuracy
accuracy2 <- (tp4 + tn4) / (tp4 + tn4 + fp4 + fn4)
accuracy2
# True Positive Rate (TPR) or Recall
tpr4 <- tp4 / (tp4 + fn4)
tpr4
# True Negative Rate (TNR) or Specificity
tnr4 <- tn4 / (tn4 + fp4)
tnr4
# False Positive Rate (FPR)
fpr4 <- fp4 / (tn4 + fp4)
fpr4
# False Negative Rate (FNR)
fnr4 <- fn4 / (tp4 +fn4)
fnr4
# Print out the results
cat("Accuracy:", accuracy2, "\n")
cat("True Positive Rate (TPR):", tpr4, "\n")
cat("True Negative Rate (TNR):", tnr4, "\n")
cat("False Positive Rate (FPR):", fpr4, "\n")
cat("False Negative Rate (FNR):", fnr4, "\n")
library(shiny)
library(ggplot2)
library(tidyr)
library(rpart)
library(corrplot)
library(writexl)
library(rpart.plot)
# Define UI
shiny::addResourcePath("www", "C:/my_shiny_app/www")
ui <- fluidPage(
tags$head(
tags$style(HTML("
body {
background-image: url('www/fire.jpg');
background-size: cover;
background-position: center;
background-repeat: no-repeat;
font-family: 'Arial', sans-serif;
}
/* Main Panel Titles */
h3, h4, h5, .tab-panel-title, .titlePanel, .sidebar-panel h3 {
color: #333333; /* Dark grey color for text */
text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.2);
font-weight: bold;
}
/* Tab Panel Titles */
.tabPanel {
font-size: 16px;
color: #555555; /* Medium grey */
font-weight: 600;
padding: 10px;
}
/* Titles in the sidebar */
.sidebar-panel h3 {
color: #FF4500; /* Orange-Red */
}
.tabPanel h4 {
color: #FF6347; /* Tomato */
}
/* Action buttons */
.action-button, .download-button {
background-color: #FF4500;
color: white;
border: none;
font-weight: bold;
padding: 10px;
border-radius: 5px;
font-family: 'Comic Sans MS', cursive;
font-size: 16px;
}
.action-button:hover, .download-button:hover {
background-color: #FF6347;
cursor: pointer;
}
/* Style for text output like confusion matrix, accuracy, etc. */
.output-text {
font-size: 14px;
color: #333333;
font-weight: 500;
line-height: 1.6;
margin: 5px 0;
}
/* Confusion Matrix tables */
table {
background-color: #FFFFFF;
width: 100%;
border-collapse: collapse;
margin-bottom: 20px;
}
table th, table td {
padding: 8px;
text-align: center;
border: 1px solid #ddd;
color: #333333;
}
table th {
background-color: #FF6347; /* Tomato background for headers */
color: white;
font-weight: bold;
}
table tr:nth-child(even) {
background-color: #f2f2f2;
}
/* Plots */
.plot-container {
margin-bottom: 20px;
}
.plot-container img {
border: 1px solid #ddd;
border-radius: 5px;
}
.plot-container .shiny-output-error {
color: #FF6347; /* Error color: Tomato */
}
"))
),
titlePanel("Smoke Pulse"),
sidebarLayout(
sidebarPanel(
h3("Data Overview"),
actionButton("load_data", "Load Data"),
actionButton("process_data", "Process Data (Remove Outliers)"),
br(),
h4("Model Evaluation"),
# Slider input for training data ratio
sliderInput("train_ratio", "Training Data Ratio:",
min = 0.5, max = 0.9, value = 0.67, step = 0.05),
actionButton("train_model", "Train Decision Tree Model"),
actionButton("train_logistic", "Train Logistic Regression"),
actionButton("test_decision_tree", "Test Decision Tree"),
actionButton("test_logistic", "Test Logistic Regression"),
br(),
h4("Accuracy and Metrics"),
verbatimTextOutput("accuracy"),
verbatimTextOutput("metrics"),
verbatimTextOutput("accuracy_test"),
verbatimTextOutput("metrics_test"),
downloadButton("download_data", "Download Processed Data")
),
mainPanel(
tabsetPanel(
tabPanel("Boxplots Before Outlier Removal", plotOutput("boxplot_before")),
tabPanel("Boxplots After Outlier Removal", plotOutput("boxplot_after")),
tabPanel("Confusion Matrix (Decision Tree)", tableOutput("conf_matrix_dt")),
tabPanel("Test Confusion Matrix (Decision Tree)", tableOutput("conf_matrix_dt_test")),
tabPanel("Confusion Matrix (Logistic Regression)", tableOutput("conf_matrix_lr")),
tabPanel("Test Confusion Matrix (Logistic Regression)", tableOutput("conf_matrix_lr_test")),
tabPanel("Correlation Matrix", plotOutput("cor_matrix")),
tabPanel("Decision Tree Plot", plotOutput("decision_tree_plot")),
tabPanel("Logistic Regression Coefficients", verbatimTextOutput("logit_coefficients"))
)
)
)
)
# Define server logic
server <- function(input, output, session) {
# Placeholder for the smoke dataset
smoke_detection <- reactiveVal()
smoke_updated_no_outliers <- reactiveVal()
model <- reactiveVal()   # Store model here
test_data <- reactiveVal()  # Store test data here
train_data <- reactiveVal()
# Load Data on button press
observeEvent(input$load_data, {
smoke_detection(read.csv("smoke_detection_iot.csv", header = TRUE, stringsAsFactors = FALSE))
smoke_updated_no_outliers(smoke_detection())
showNotification("Data Loaded Successfully", type = "message")
})
# Process Data (Remove Outliers)
observeEvent(input$process_data, {
data <- smoke_detection()
exclude_columns <- c("UTC", "Fire.Alarm")
# Removing outliers logic
for (col_name in names(data)) {
if (is.numeric(data[[col_name]]) && !(col_name %in% exclude_columns)) {
Q1 <- quantile(data[[col_name]], 0.25, na.rm = TRUE)
Q3 <- quantile(data[[col_name]], 0.75, na.rm = TRUE)
IQR_value <- Q3 - Q1
lower_bound <- Q1 - 1.5 * IQR_value
upper_bound <- Q3 + 1.5 * IQR_value
data <- data[data[[col_name]] >= lower_bound & data[[col_name]] <= upper_bound, ]
}
}
smoke_updated_no_outliers(data)
showNotification("Outliers Removed", type = "message")
})
# Plot Boxplots Before Outlier Removal
output$boxplot_before <- renderPlot({
data <- smoke_detection()
par(mfrow = c(2, 2))
boxplot(data$Temperature.C., main = "Temperature.C.", col = "lightblue", border = "black", ylab = "Temperature (°C)")
boxplot(data$Humidity..., main = "Humidity...", col = "lightgreen", border = "black", ylab = "Humidity (%)")
boxplot(data$TVOC.ppb., main = "TVOC.ppb.", col = "lightcoral", border = "black", ylab = "TVOC (ppb)")
boxplot(data$Raw.H2, main = "Raw.H2", col = "lightyellow", border = "black", ylab = "Raw.H2")
par(mfrow = c(1, 1))
})
# Plot Boxplots After Outlier Removal
output$boxplot_after <- renderPlot({
data <- smoke_updated_no_outliers()
par(mfrow = c(2, 2))
boxplot(data$Temperature.C., main = "Temperature.C.", col = "lightblue", border = "black", ylab = "Temperature (°C)")
boxplot(data$Humidity..., main = "Humidity...", col = "lightgreen", border = "black", ylab = "Humidity (%)")
boxplot(data$TVOC.ppb., main = "TVOC.ppb.", col = "lightcoral", border = "black", ylab = "TVOC (ppb)")
boxplot(data$Raw.H2, main = "Raw.H2", col = "lightyellow", border = "black", ylab = "Raw.H2")
par(mfrow = c(1, 1))
})
# Train Decision Tree Model
observeEvent(input$train_model, {
data <- smoke_updated_no_outliers()
# Get the user-specified training ratio
train_ratio <- input$train_ratio
# Split data into training and testing sets based on the ratio
set.seed(345)
train_index <- sample(1:nrow(data), nrow(data) * train_ratio)
train_data(data[train_index, ])
test_data(data[-train_index, ])
# Store the train and test data in reactive values
# train_data(train_data_)
#test_data(test_data_)
fit <- rpart(Fire.Alarm ~ ., data = train_data(), method = "class", control = rpart.control(xval=0,minsplit = 50,
minbucket = 0.0001,
maxdepth = 30,
cp = 0.00001))
model(fit)
#test_data(test_data_)
# Decision Tree Plot
output$decision_tree_plot <- renderPlot({
rpart.plot(fit, type = 1, extra = 1)
})
# Confusion Matrix (Decision Tree) Train
smoke_detection_pred <- predict(fit, train_data(), type = "class")
smoke_detection_actual <- train_data()$Fire.Alarm
confusion_matrix <- table(smoke_detection_pred, smoke_detection_actual)
output$conf_matrix_dt <- renderTable({ confusion_matrix })
# Confusion Matrix (Decision Tree) Test
smoke_detection_pred_test <- predict(fit, test_data(), type = "class")
smoke_detection_actual_test <- test_data()$Fire.Alarm
confusion_matrix_test <- table(smoke_detection_pred_test, smoke_detection_actual_test)
output$conf_matrix_dt_test <- renderTable({ confusion_matrix_test })
# Accuracy (Training Set)
smoke_detection_pred_train <- predict(fit, train_data(), type = "class")
smoke_detection_actual_train <- train_data()$Fire.Alarm
confusion_matrix_train <- table(smoke_detection_pred_train, smoke_detection_actual_train)
pt_train <- prop.table(confusion_matrix_train)
accuracy_train <- pt_train[1, 1] + pt_train[2, 2]
# Accuracy (Test Set)
pt_test <- prop.table(confusion_matrix_test)
accuracy_test <- pt_test[1, 1] + pt_test[2, 2]
# Display Accuracy Results
output$accuracy <- renderText({
paste("Training Accuracy: ", round(accuracy_train, 4), "\nTesting Accuracy: ", round(accuracy_test, 4))
# Accuracy and Metrics for Logistic Regression
tp1 <- confusion_matrix_train[2, 2]
tn1 <- confusion_matrix_train[1, 1]
fp1 <- confusion_matrix_train[2, 1]
fn1 <- confusion_matrix_train[1, 2]
tpr1 <- tp1 / (tp1 + fn1)
tnr1 <- tn1 / (tn1 + fp1)
fpr1 <- fp1 / (tn1 + fp1)
fnr1 <- fn1 / (tp1 + fn1)
output$accuracy <- renderText({
paste("Accuracy: ", round(accuracy_train, 4))
})
output$metrics <- renderText({
paste("True Positive Rate (TPR):", round(tpr1, 4),
"\nTrue Negative Rate (TNR):", round(tnr1, 4),
"\nFalse Positive Rate (FPR):", round(fpr1, 4),
"\nFalse Negative Rate (FNR):", round(fnr1, 4))
})
})
})
# Test Decision Tree Model on the Test Set
observeEvent(input$test_decision_tree, {
fit <- model()  # Get the trained model
#train_data_ <- train_data()  # Access stored training data
#test_data_ <- test_data()    # Access stored testing data
if (!is.null(train_data() ) && !is.null(test_data())) {
# Make predictions on the test data
smoke_detection_pred_test <- predict(fit, test_data(), type = "class")
smoke_detection_actual_test <- test_data()$Fire.Alarm
confusion_matrix_test <- table(smoke_detection_pred_test, smoke_detection_actual_test)
# Show confusion matrix for test data
output$conf_matrix_dt_test <- renderTable({
confusion_matrix_test
})
# Calculate accuracy for test data
pt_test <- prop.table(confusion_matrix_test)
accuracy_test <- pt_test[1, 1] + pt_test[2, 2]
output$accuracy <- renderText({
paste("Test Accuracy: ", round(accuracy_test, 4))
})
# Metrics for test data
tp_test <- confusion_matrix_test[2, 2]
tn_test <- confusion_matrix_test[1, 1]
fp_test <- confusion_matrix_test[2, 1]
fn_test <- confusion_matrix_test[1, 2]
tpr_test <- tp_test / (tp_test + fn_test)
tnr_test <- tn_test / (tn_test + fp_test)
fpr_test <- fp_test / (tn_test + fp_test)
fnr_test <- fn_test / (tp_test + fn_test)
output$metrics <- renderText({
paste("Test Metrics:\nTrue Positive Rate (TPR):", round(tpr_test, 4),
"\nTrue Negative Rate (TNR):", round(tnr_test, 4),
"\nFalse Positive Rate (FPR):", round(fpr_test, 4),
"\nFalse Negative Rate (FNR):", round(fnr_test, 4))
})
} else {
showNotification("Please train the Decision Tree model first.", type = "error")
}
})
train_data <- reactiveVal(NULL)
test_data <- reactiveVal(NULL)
logistic_model <- reactiveVal(NULL)
# Train Logistic Regression Model
observeEvent(input$train_logistic, {
tryCatch({
# Ensure that the data has no missing values
data <- smoke_updated_no_outliers()
data <- na.omit(data)  # Remove rows with missing values
# Ensure the response variable 'Fire.Alarm' is a factor (binary classification)
data$Fire.Alarm <- as.factor(data$Fire.Alarm)
# Get the user-specified training ratio
train_ratio <- input$train_ratio
# Split data into training and testing sets based on the ratio
set.seed(345)
train_index <- sample(1:nrow(data), nrow(data) * train_ratio)
train_data(data[train_index, ])
test_data(data[-train_index, ])
# Train the logistic regression model
logit.reg <- glm(Fire.Alarm ~ ., data = train_data(), family = "binomial")
# Store the trained model in the logistic_model reactive value
logistic_model(logit.reg)
# Logistic Regression Coefficients
logit_coeff <- summary(logit.reg)$coefficients
output$logit_coefficients <- renderText({
paste("Logistic Regression Coefficients:\n", capture.output(print(logit_coeff)), collapse = "\n")
})
# Predict and Confusion Matrix (Logistic Regression)
logit_predict <- predict(logit.reg, train_data(), type = "response")
logit_predict_class <- ifelse(logit_predict > 0.5, 1, 0)
# Ensure factors are in the correct order
logit_predict_class <- factor(logit_predict_class, levels = c(0, 1))
actual_values <- factor(train_data()$Fire.Alarm, levels = c(0, 1))
cm <- table(Predicted = logit_predict_class, Actual = actual_values)
output$conf_matrix_lr <- renderTable({ cm })
# Accuracy and Metrics for Logistic Regression
tp <- cm[2, 2]
tn <- cm[1, 1]
fp <- cm[2, 1]
fn <- cm[1, 2]
accuracy <- (tp + tn) / (tp + tn + fp + fn)
tpr <- tp / (tp + fn)
tnr <- tn / (tn + fp)
fpr <- fp / (tn + fp)
fnr <- fn / (tp + fn)
output$accuracy <- renderText({
paste("Training Accuracy: ", round(accuracy, 4))
})
output$metrics <- renderText({
paste("True Positive Rate (TPR):", round(tpr, 4),
"\nTrue Negative Rate (TNR):", round(tnr, 4),
"\nFalse Positive Rate (FPR):", round(fpr, 4),
"\nFalse Negative Rate (FNR):", round(fnr, 4))
})
}, error = function(e) {
showNotification("Error in training logistic regression model.", type = "error")
})
})
train_data <- reactiveVal(NULL)
test_data <- reactiveVal(NULL)
logistic_model <- reactiveVal(NULL)
# Test Logistic Regression Model
observeEvent(input$test_logistic, {
tryCatch({
# Ensure the model is trained before testing
if (is.null(logistic_model())) {
showNotification("Model not trained yet!", type = "error")
return(NULL)
}
print("Using the following logistic model for testing:")
print(logistic_model())
# Get the trained logistic regression model
logit.reg <- logistic_model()
test_data_set <- test_data()
# Make predictions on the test data
logit_predict_test <- predict(logit.reg, test_data_set, type = "response")
logit_predict_class_test <- ifelse(logit_predict_test > 0.5, 1, 0)
logit_predict_class_test <- factor(logit_predict_class_test, levels = c(0, 1))
actual_values_test <- factor(test_data_set$Fire.Alarm, levels = c(0, 1))
cm_test <- table(Predicted = logit_predict_class_test, Actual = actual_values_test)
output$conf_matrix_lr_test <- renderTable({ cm_test })
# Accuracy and Metrics for Logistic Regression (Test Data)
tp_test <- cm_test[2, 2]
tn_test <- cm_test[1, 1]
fp_test <- cm_test[2, 1]
fn_test <- cm_test[1, 2]
accuracy_test <- (tp_test + tn_test) / (tp_test + tn_test + fp_test + fn_test)
tpr_test <- tp_test / (tp_test + fn_test)
tnr_test <- tn_test / (tn_test + fp_test)
fpr_test <- fp_test / (tn_test + fp_test)
fnr_test <- fn_test / (tp_test + fn_test)
output$accuracy_test <- renderText({
paste("Testing Accuracy: ", round(accuracy_test, 4))
})
output$metrics_test <- renderText({
paste("True Positive Rate (TPR):", round(tpr_test, 4),
"\nTrue Negative Rate (TNR):", round(tnr_test, 4),
"\nFalse Positive Rate (FPR):", round(fpr_test, 4),
"\nFalse Negative Rate (FNR):", round(fnr_test, 4))
})
}, error = function(e) {
showNotification("Error in testing logistic regression model.", type = "error")
})
})
# Correlation Matrix Plot
output$cor_matrix <- renderPlot({
data <- smoke_updated_no_outliers()
cor_data <- cor(data[sapply(data, is.numeric)], use = "complete.obs")
corrplot(cor_data, method = "circle")
})
# Download Processed Data
output$download_data <- downloadHandler(
filename = function() {
paste("processed_smoke_data.xlsx")
},
content = function(file) {
write_xlsx(smoke_updated_no_outliers(), file)
}
)
}
# Run the application
shinyApp(ui = ui, server = server)
